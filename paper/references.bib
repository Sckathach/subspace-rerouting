@article{elhage_mathematical_2021,
   title={A Mathematical Framework for Transformer Circuits},
   author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and DasSarma, Nova and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
   year={2021},
   journal={Transformer Circuits Thread},
   note={https://transformer-circuits.pub/2021/framework/index.html}
}

@misc{casper_interpretability_2023,
  title={EIS IX: Interpretability and Adversaries},
  author={Stephen Casper},
  year={2023}
}

@misc{agrawal_pixtral_2024,
      title={Pixtral 12B}, 
      author={Pravesh Agrawal and Szymon Antoniak and Emma Bou Hanna and Baptiste Bout and Devendra Chaplot and Jessica Chudnovsky and Diogo Costa and Baudouin De Monicault and Saurabh Garg and Theophile Gervet and Soham Ghosh and Amélie Héliou and Paul Jacob and Albert Q. Jiang and Kartik Khandelwal and Timothée Lacroix and Guillaume Lample and Diego Las Casas and Thibaut Lavril and Teven Le Scao and Andy Lo and William Marshall and Louis Martin and Arthur Mensch and Pavankumar Muddireddy and Valera Nemychnikova and Marie Pellat and Patrick Von Platen and Nikhil Raghuraman and Baptiste Rozière and Alexandre Sablayrolles and Lucile Saulnier and Romain Sauvestre and Wendy Shang and Roman Soletskyi and Lawrence Stewart and Pierre Stock and Joachim Studnia and Sandeep Subramanian and Sagar Vaze and Thomas Wang and Sophia Yang},
      year={2024},
      eprint={2410.07073},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}

@misc{touvron_llama_2023,
      title={LLaMA: Open and Efficient Foundation Language Models}, 
      author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
      year={2023},
      eprint={2302.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@article{liu_exploring_2024,
      title={Exploring Vulnerabilities and Protections in Large Language Models: A Survey}, 
      author={Frank Weizhen Liu and Chenhui Hu},
      year={2024},
      eprint={2406.00240},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{schulhoff_ignore_2024,
      title={Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition}, 
      author={Sander Schulhoff and Jeremy Pinto and Anaum Khan and Louis-François Bouchard and Chenglei Si and Svetlina Anati and Valen Tagliabue and Anson Liu Kost and Christopher Carnahan and Jordan Boyd-Graber},
      year={2024},
      eprint={2311.16119},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
}

@article{rumbelow_solidgoldmagikarp_2023,
    author = {Jessica Rumbelow and Mwatkins},
    title = {SolidGoldMagikarp (plus, prompt generation)},
    journal = {MATS Program},
    year = {2023},
}

@article{zou_poisonedrag_2024,
      title={PoisonedRAG: Knowledge Poisoning Attacks to Retrieval-Augmented Generation of Large Language Models},
      author={Wei Zou and Runpeng Geng and Binghui Wang and Jinyuan Jia},
      year={2024},
      eprint={2402.07867},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
}

@article{anthropic_many_2024,
  title={Many-shot jailbreaking},
  author={Anthropic},
  year={2024}
}

@article{chaudhari_phantom_2024,
      title={Phantom: General Trigger Attacks on Retrieval Augmented Language Generation}, 
      author={Harsh Chaudhari and Giorgio Severi and John Abascal and Matthew Jagielski and Christopher A. Choquette-Choo and Milad Nasr and Cristina Nita-Rotaru and Alina Oprea},
      year={2024},
      eprint={2405.20485},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
}

@misc{nestaas_adversarial_2024,
	title = {Adversarial Search Engine Optimization for Large Language Models},
	abstract = {Large Language Models ({LLMs}) are increasingly used in applications where the model selects from competing third-party content, such as in {LLM}-powered search engines or chatbot plugins. In this paper, we introduce Preference Manipulation Attacks, a new class of attacks that manipulate an {LLM}’s selections to favor the attacker. We demonstrate that carefully crafted website content or plugin documentations can trick an {LLM} to promote the attacker products and discredit competitors, thereby increasing user traffic and monetization. We show this can lead to a prisoner’s dilemma, where all parties are incentivized to launch attacks, but this collectively degrades the {LLM}’s outputs for everyone. We demonstrate our attacks on production {LLM} search engines (Bing and Perplexity) and plugin {APIs} (for {GPT}-4 and Claude). As {LLMs} are increasingly used to rank third-party content, we expect Preference Manipulation Attacks to emerge as a significant threat.},
	number = {{arXiv}:2406.18382},
	publisher = {{arXiv}},
	author = {Nestaas, Fredrik and Debenedetti, Edoardo and Tramèr, Florian},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2406.18382 [cs]},
  year = {2024},
	keywords = {adv, llm, rag},
}

@article{chen_struq_2024,
	title = {{StruQ}: Defending Against Prompt Injection with Structured Queries},
	shorttitle = {{StruQ}},
	abstract = {Recent advances in Large Language Models ({LLMs}) enable exciting {LLM}-integrated applications, which perform textbased tasks by utilizing their advanced language understanding capabilities. However, as {LLMs} have improved, so have the attacks against them. Prompt injection attacks are an important threat: they trick the model to deviate from the original application’s instructions and instead follow user directives. These attacks rely on the {LLM}’s ability to follow instructions and inability to separate the prompts and user data. We introduce structured queries, a general approach to tackle this problem. Structured queries separate prompts and data into two channels. We implement a system that supports structured queries. This system is made of (1) a secure front-end that formats a prompt and user data into a special format, and (2) a specially trained {LLM} that can produce highquality outputs from these inputs. The {LLM} is trained using a novel fine-tuning strategy: we convert a base (non-instructiontuned) {LLM} to a structured instruction-tuned model that will only follow instructions in the prompt portion of a query. To do so, we augment standard instruction tuning datasets with examples that also include instructions in the data portion of the query, and fine-tune the model to ignore these. Our system significantly improves resistance to prompt injection attacks, with little or no impact on utility. Our code is released here.},
	number = {{arXiv}:2402.06363},
	publisher = {{arXiv}},
	author = {Chen, Sizhe and Piet, Julien and Sitawarin, Chawin and Wagner, David},
	langid = {english},
	eprinttype = {arxiv},
  year = {2024},
	eprint = {2402.06363 [cs]},
	keywords = {llm, def},
}

@article{wallace_instruction_2024,
      title={The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions}, 
      author={Eric Wallace and Kai Xiao and Reimar Leike and Lilian Weng and Johannes Heidecke and Alex Beutel},
      year={2024},
      eprint={2404.13208},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
}

@article{xiang_certifiable_2024,
      title={Certifiably Robust RAG against Retrieval Corruption}, 
      author={Chong Xiang and Tong Wu and Zexuan Zhong and David Wagner and Danqi Chen and Prateek Mittal},
      year={2024},
      eprint={2405.15556},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{piet_jatmo_2024,
      title={Jatmo: Prompt Injection Defense by Task-Specific Finetuning}, 
      author={Julien Piet and Maha Alrashed and Chawin Sitawarin and Sizhe Chen and Zeming Wei and Elizabeth Sun and Basel Alomair and David Wagner},
      year={2024},
      eprint={2312.17673},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
}

@book{amos_amortized_2023,
      title={Tutorial on amortized optimization}, 
      author={Brandon Amos},
      year={2023},
      eprint={2202.00665},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{zou_universal_2023,
      title={Universal and Transferable Adversarial Attacks on Aligned Language Models}, 
      author={Andy Zou and Zifan Wang and Nicholas Carlini and Milad Nasr and J. Zico Kolter and Matt Fredrikson},
      year={2023},
      eprint={2307.15043},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}



@article{paulus_advprompter_2024,
	title = {{AdvPrompter}: Fast Adaptive Adversarial Prompting for {LLMs}},
	shorttitle = {{AdvPrompter}},
	abstract = {While recently Large Language Models ({LLMs}) have achieved remarkable successes, they are vulnerable to certain jailbreaking attacks that lead to generation of inappropriate or harmful content. Manual red-teaming requires finding adversarial prompts that cause such jailbreaking, e.g. by appending a suffix to a given instruction, which is inefficient and time-consuming. On the other hand, automatic adversarial prompt generation often leads to semantically meaningless attacks that can easily be detected by perplexity-based filters, may require gradient information from the {TargetLLM}, or do not scale well due to time-consuming discrete optimization processes over the token space. In this paper, we present a novel method that uses another {LLM}, called the {AdvPrompter}, to generate human-readable adversarial prompts in seconds, \${\textbackslash}sim800{\textbackslash}times\$ faster than existing optimization-based approaches. We train the {AdvPrompter} using a novel algorithm that does not require access to the gradients of the {TargetLLM}. This process alternates between two steps: (1) generating high-quality target adversarial suffixes by optimizing the {AdvPrompter} predictions, and (2) low-rank fine-tuning of the {AdvPrompter} with the generated adversarial suffixes. The trained {AdvPrompter} generates suffixes that veil the input instruction without changing its meaning, such that the {TargetLLM} is lured to give a harmful response. Experimental results on popular open source {TargetLLMs} show state-of-the-art results on the {AdvBench} dataset, that also transfer to closed-source black-box {LLM} {APIs}. Further, we demonstrate that by fine-tuning on a synthetic dataset generated by {AdvPrompter}, {LLMs} can be made more robust against jailbreaking attacks while maintaining performance, i.e. high {MMLU} scores.},
	number = {{arXiv}:2404.16873},
	publisher = {{arXiv}},
	author = {Paulus, Anselm and Zharmagambetov, Arman and Guo, Chuan and Amos, Brandon and Tian, Yuandong},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2404.16873 [cs]},
  year = {2024},
	keywords = {adv, llm, prompt-hacking},
}

@article{jain_baseline_2023,
      title={Baseline Defenses for Adversarial Attacks Against Aligned Language Models}, 
      author={Neel Jain and Avi Schwarzschild and Yuxin Wen and Gowthami Somepalli and John Kirchenbauer and Ping-yeh Chiang and Micah Goldblum and Aniruddha Saha and Jonas Geiping and Tom Goldstein},
      year={2023},
      eprint={2309.00614},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{samvelyan_rainbow_2024,
      title={Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts}, 
      author={Mikayel Samvelyan and Sharath Chandra Raparthy and Andrei Lupu and Eric Hambro and Aram H. Markosyan and Manish Bhatt and Yuning Mao and Minqi Jiang and Jack Parker-Holder and Jakob Foerster and Tim Rocktäschel and Roberta Raileanu},
      year={2024},
      eprint={2402.16822},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@article{mouret_illuminating_2015,
      title={Illuminating search spaces by mapping elites}, 
      author={Jean-Baptiste Mouret and Jeff Clune},
      year={2015},
      eprint={1504.04909},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
}

@article{wan_cyberseceval3_2024,
      title = {CyberSecEval 3: Advancing the Evaluation of Cybersecurity Risks and Capabilities in Large Language Models},
      author = {Shengye Wan, Cyrus Nikolaidis, Daniel Song, David Molnar, James Crnkovich, Jayson Grace, Manish Bhatt, Sahana Chennabasappa, Spencer Whitman, Stephanie Ding, Vlad Ionescu, Yue Li, Joshua Saxe},
      year = {2024},
      archivePrefix = {arXiv},
}

@article{inan_llamaguard_2024,
      title = {Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations},
      author = {Hakan Inan and Kartikeya Upasani and Jianfeng Chi and Rashi Rungta and Krithika Iyer and Yuning Mao and Davide Testuggine and Madian Khabsa},
      year = {2024},
      archivePrefix = {arXiv}
}

@article{sharma_spml_2024,
      title={SPML: A DSL for Defending Language Models Against Prompt Attacks}, 
      author={Reshabh K Sharma and Vinayak Gupta and Dan Grossman},
      year={2024},
      eprint={2402.11755},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{xiong_defensive_2024,
      title={Defensive Prompt Patch: A Robust and Interpretable Defense of LLMs against Jailbreak Attacks}, 
      author={Chen Xiong and Xiangyu Qi and Pin-Yu Chen and Tsung-Yi Ho},
      year={2024},
      eprint={2405.20099},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
}

@article{li_wmdp_2024,
      title={The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning}, 
      author={Nathaniel Li and Alexander Pan and Anjali Gopal and Summer Yue and Daniel Berrios and Alice Gatti and Justin D. Li and Ann-Kathrin Dombrowski and Shashwat Goel and Long Phan and Gabriel Mukobi and Nathan Helm-Burger and Rassin Lababidi and Lennart Justen and Andrew B. Liu and Michael Chen and Isabelle Barrass and Oliver Zhang and Xiaoyuan Zhu and Rishub Tamirisa and Bhrugu Bharathi and Adam Khoja and Zhenqi Zhao and Ariel Herbert-Voss and Cort B. Breuer and Samuel Marks and Oam Patel and Andy Zou and Mantas Mazeika and Zifan Wang and Palash Oswal and Weiran Lin and Adam A. Hunt and Justin Tienken-Harder and Kevin Y. Shih and Kemper Talley and John Guan and Russell Kaplan and Ian Steneker and David Campbell and Brad Jokubaitis and Alex Levinson and Jean Wang and William Qian and Kallol Krishna Karmakar and Steven Basart and Stephen Fitz and Mindy Levine and Ponnurangam Kumaraguru and Uday Tupakula and Vijay Varadharajan and Ruoyu Wang and Yan Shoshitaishvili and Jimmy Ba and Kevin M. Esvelt and Alexandr Wang and Dan Hendrycks},
      year={2024},
      eprint={2403.03218},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{conmy_automated_2023,
      title={Towards Automated Circuit Discovery for Mechanistic Interpretability}, 
      author={Arthur Conmy and Augustine N. Mavor-Parker and Aengus Lynch and Stefan Heimersheim and Adrià Garriga-Alonso},
      year={2023},
      eprint={2304.14997},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{turner_activation_2024,
      title={Activation Addition: Steering Language Models Without Optimization}, 
      author={Alexander Matt Turner and Lisa Thiergart and Gavin Leech and David Udell and Juan J. Vazquez and Ulisse Mini and Monte MacDiarmid},
      year={2024},
      eprint={2308.10248},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@article{mehrotra_tree_2023,
      title={Tree of Attacks: Jailbreaking Black-Box LLMs Automatically}, 
      author={Anay Mehrotra and Manolis Zampetakis and Paul Kassianik and Blaine Nelson and Hyrum Anderson and Yaron Singer and Amin Karbasi},
      year={2024},
      eprint={2312.02119},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@misc{yu_gptfuzzer_2024,
      title={GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts}, 
      author={Jiahao Yu and Xingwei Lin and Zheng Yu and Xinyu Xing},
      year={2024},
      eprint={2309.10253},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
}

@article{zhao_weak_2024,
      title={Weak-to-Strong Jailbreaking on Large Language Models}, 
      author={Xuandong Zhao and Xianjun Yang and Tianyu Pang and Chao Du and Lei Li and Yu-Xiang Wang and William Yang Wang},
      year={2024},
      eprint={2401.17256},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@article{li_llm_2024,
      title={LLM Defenses Are Not Robust to Multi-Turn Human Jailbreaks Yet}, 
      author={Nathaniel Li and Ziwen Han and Ian Steneker and Willow Primack and Riley Goodside and Hugh Zhang and Zifan Wang and Cristina Menghini and Summer Yue},
      year={2024},
      eprint={2408.15221},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{wang_hidden_2024,
      title={Hidden You Malicious Goal Into Benign Narratives: Jailbreak Large Language Models through Logic Chain Injection}, 
      author={Zhilong Wang and Yebo Cao and Peng Liu},
      year={2024},
      eprint={2404.04849},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
}

@article{yang_chain_2024,
      title={Chain of Attack: a Semantic-Driven Contextual Multi-Turn attacker for LLM}, 
      author={Xikang Yang and Xuehai Tang and Songlin Hu and Jizhong Han},
      year={2024},
      eprint={2405.05610},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@article{russinovich_great_2024,
      title={Great, Now Write an Article About That: The Crescendo Multi-Turn LLM Jailbreak Attack}, 
      author={Mark Russinovich and Ahmed Salem and Ronen Eldan},
      year={2024},
      eprint={2404.01833},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
}

@article{cheng_leveraging_2024,
      title={Leveraging the Context through Multi-Round Interactions for Jailbreaking Attacks}, 
      author={Yixin Cheng and Markos Georgopoulos and Volkan Cevher and Grigorios G. Chrysos},
      year={2024},
      eprint={2402.09177},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{arditi_refusal_2024,
      title={Refusal in Language Models Is Mediated by a Single Direction}, 
      author={Andy Arditi and Oscar Obeso and Aaquib Syed and Daniel Paleka and Nina Panickssery and Wes Gurnee and Neel Nanda},
      year={2024},
      eprint={2406.11717},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{sheshadri_latent_2024,
      title={Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs}, 
      author={Abhay Sheshadri and Aidan Ewart and Phillip Guo and Aengus Lynch and Cindy Wu and Vivek Hebbar and Henry Sleight and Asa Cooper Stickland and Ethan Perez and Dylan Hadfield-Menell and Stephen Casper},
      year={2024},
      eprint={2407.15549},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{ilharco_editing_2023,
      title={Editing Models with Task Arithmetic}, 
      author={Gabriel Ilharco and Marco Tulio Ribeiro and Mitchell Wortsman and Suchin Gururangan and Ludwig Schmidt and Hannaneh Hajishirzi and Ali Farhadi},
      year={2023},
      eprint={2212.04089},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}



@article{zhang_interpretability_2024,
      title={Beyond Interpretability: The Gains of Feature Monosemanticity on Model Robustness}, 
      author={Qi Zhang and Yifei Wang and Jingyi Cui and Xiang Pan and Qi Lei and Stefanie Jegelka and Yisen Wang},
      year={2024},
      eprint={2410.21331},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}



@article{wortsman_modelsoups_2022,
      title={Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time}, 
      author={Mitchell Wortsman and Gabriel Ilharco and Samir Yitzhak Gadre and Rebecca Roelofs and Raphael Gontijo-Lopes and Ari S. Morcos and Hongseok Namkoong and Ali Farhadi and Yair Carmon and Simon Kornblith and Ludwig Schmidt},
      year={2022},
      eprint={2203.05482},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{lucas_analyzing_2021,
      title={Analyzing Monotonic Linear Interpolation in Neural Network Loss Landscapes}, 
      author={James Lucas and Juhan Bae and Michael R. Zhang and Stanislav Fort and Richard Zemel and Roger Grosse},
      year={2021},
      eprint={2104.11044},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{izmailov_averaging_2019,
      title={Averaging Weights Leads to Wider Optima and Better Generalization}, 
      author={Pavel Izmailov and Dmitrii Podoprikhin and Timur Garipov and Dmitry Vetrov and Andrew Gordon Wilson},
      year={2019},
      eprint={1803.05407},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{ilharco_patching_2022,
      title={Patching open-vocabulary models by interpolating weights}, 
      author={Gabriel Ilharco and Mitchell Wortsman and Samir Yitzhak Gadre and Shuran Song and Hannaneh Hajishirzi and Simon Kornblith and Ali Farhadi and Ludwig Schmidt},
      year={2022},
      eprint={2208.05592},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}



@article{olsson_incontext_2022,
      title={In-context Learning and Induction Heads}, 
      author={Catherine Olsson and Nelson Elhage and Neel Nanda and Nicholas Joseph and Nova DasSarma and Tom Henighan and Ben Mann and Amanda Askell and Yuntao Bai and Anna Chen and Tom Conerly and Dawn Drain and Deep Ganguli and Zac Hatfield-Dodds and Danny Hernandez and Scott Johnston and Andy Jones and Jackson Kernion and Liane Lovitt and Kamal Ndousse and Dario Amodei and Tom Brown and Jack Clark and Jared Kaplan and Sam McCandlish and Chris Olah},
      year={2022},
      eprint={2209.11895},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}


@article{obrien_steering_2024,
      title={Steering Language Model Refusal with Sparse Autoencoders}, 
      author={Kyle O'Brien and David Majercak and Xavier Fernandes and Richard Edgar and Jingya Chen and Harsha Nori and Dean Carignan and Eric Horvitz and Forough Poursabzi-Sangde},
      year={2024},
      eprint={2411.11296},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@misc{zhou_role_2024,
      title={On the Role of Attention Heads in Large Language Model Safety}, 
      author={Zhenhong Zhou and Haiyang Yu and Xinghua Zhang and Rongwu Xu and Fei Huang and Kun Wang and Yang Liu and Junfeng Fang and Yongbin Li},
      year={2024},
      eprint={2410.13708},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@article{power_grokking_2022,
      title={Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets}, 
      author={Alethea Power and Yuri Burda and Harri Edwards and Igor Babuschkin and Vedant Misra},
      year={2022},
      eprint={2201.02177},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{pan_effect_2022,
      title={The Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models}, 
      author={Alexander Pan and Kush Bhatia and Jacob Steinhardt},
      year={2022},
      eprint={2201.03544},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{bricken_monosemanticity_2023,
     title={Towards Monosemanticity: Decomposing Language Models With Dictionary Learning},
     author={Bricken, Trenton and Templeton, Adly and Batson, Joshua and Chen, Brian and Jermyn, Adam and Conerly, Tom and Turner, Nick and Anil, Cem and Denison, Carson and Askell, Amanda and Lasenby, Robert and Wu, Yifan and Kravec, Shauna and Schiefer, Nicholas and Maxwell, Tim and Joseph, Nicholas and Hatfield-Dodds, Zac and Tamkin, Alex and Nguyen, Karina and McLean, Brayden and Burke, Josiah E and Hume, Tristan and Carter, Shan and Henighan, Tom and Olah, Christopher},
     year={2023},
     journal={Transformer Circuits Thread},
     note={https://transformer-circuits.pub/2023/monosemantic-features/index.html}
}


@article{chao_jailbreaking_2024,
      title={Jailbreaking Black Box Large Language Models in Twenty Queries}, 
      author={Patrick Chao and Alexander Robey and Edgar Dobriban and Hamed Hassani and George J. Pappas and Eric Wong},
      year={2024},
      eprint={2310.08419},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{fiottokaufman_nnsight_2025,
      title={NNsight and NDIF: Democratizing Access to Open-Weight Foundation Model Internals}, 
      author={Jaden Fiotto-Kaufman and Alexander R. Loftus and Eric Todd and Jannik Brinkmann and Koyena Pal and Dmitrii Troitskii and Michael Ripa and Adam Belfki and Can Rager and Caden Juang and Aaron Mueller and Samuel Marks and Arnab Sen Sharma and Francesca Lucchetti and Nikhil Prakash and Carla Brodley and Arjun Guha and Jonathan Bell and Byron C. Wallace and David Bau},
      year={2025},
      eprint={2407.14561},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{ebrahimi_hotflip_2018,
      title={HotFlip: White-Box Adversarial Examples for Text Classification}, 
      author={Javid Ebrahimi and Anyi Rao and Daniel Lowd and Dejing Dou},
      year={2018},
      eprint={1712.06751},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@article{cornacchia_moje_2024,
      title={MoJE: Mixture of Jailbreak Experts, Naive Tabular Classifiers as Guard for Prompt Attacks}, 
      author={Giandomenico Cornacchia and Giulio Zizzo and Kieran Fraser and Muhammad Zaid Hameed and Ambrish Rawat and Mark Purcell},
      year={2024},
      eprint={2409.17699},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
}

@article{garak,
  title={{garak: A Framework for Security Probing Large Language Models}},
  author={Leon Derczynski and Erick Galinkin and Jeffrey Martin and Subho Majumdar and Nanna Inie},
  year={2024},
}


@article{nasr_scalable_2023,
      title={Scalable Extraction of Training Data from (Production) Language Models}, 
      author={Milad Nasr and Nicholas Carlini and Jonathan Hayase and Matthew Jagielski and A. Feder Cooper and Daphne Ippolito and Christopher A. Choquette-Choo and Eric Wallace and Florian Tramèr and Katherine Lee},
      year={2023},
      eprint={2311.17035},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{ji_beavertails_2023,
      title={BeaverTails: Towards Improved Safety Alignment of LLM via a Human-Preference Dataset}, 
      author={Jiaming Ji and Mickel Liu and Juntao Dai and Xuehai Pan and Chi Zhang and Ce Bian and Chi Zhang and Ruiyang Sun and Yizhou Wang and Yaodong Yang},
      year={2023},
      eprint={2307.04657},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}


@article{huang_endless_2024,
  title={Endless Jailbreaks with Bijection Learning},
  author={Huang, Brian R.Y. and Li, Maximilian and Tang, Leonard},
  journal={arXiv preprint arXiv:2410.01294},
  year={2024},
  note={Haize Labs}
}

@misc{olah_distributed_2023,
      title={Distributed Representations: Composition & Superposition},
      author={Chris Olah},
      jounal={Transformer Circuit Thread},
      year={2023},
}

@article{cunningham_sparse_2023,
      title={Sparse Autoencoders Find Highly Interpretable Features in Language Models}, 
      author={Hoagy Cunningham and Aidan Ewart and Logan Riggs and Robert Huben and Lee Sharkey},
      year={2023},
      eprint={2309.08600},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}


@misc{openai_gpt4o_2024,
      title={OpenAI o1 System Card},
      author={OpenAI},
      year={2024},
}

@article{openai_language_2023,
      title={Language models can explain neurons in language models},
      author={OpenAI},
      year={2023},
}


@article{liu_autodan_2024,
      title={AutoDAN-Turbo: A Lifelong Agent for Strategy Self-Exploration to Jailbreak LLMs}, 
      author={Xiaogeng Liu and Peiran Li and Edward Suh and Yevgeniy Vorobeychik and Zhuoqing Mao and Somesh Jha and Patrick McDaniel and Huan Sun and Bo Li and Chaowei Xiao},
      year={2024},
      eprint={2410.05295},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
}

@article{mo_fight_2024,
      title={Fight Back Against Jailbreaking via Prompt Adversarial Tuning}, 
      author={Yichuan Mo and Yuji Wang and Zeming Wei and Yisen Wang},
      year={2024},
      eprint={2402.06255},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{guth_rainbow_2023,
  title={A Rainbow in Deep Network Black Boxes},
  author={Guth, Florentin and M{\'e}nard, Brice and Rochette, Gaspar and Mallat, St{\'e}phane},
  journal={arXiv preprint arXiv:2305.18512},
  year={2023}
}

@article{mersha_explainable_2025,
      title={Explainable Artificial Intelligence: A Survey of Needs, Techniques, Applications, and Future Direction}, 
      author={Melkamu Mersha and Khang Lam and Joseph Wood and Ali AlShami and Jugal Kalita},
      year={2025},
      eprint={2409.00265},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
}

@article{wei_jailbroken_2023,
      title={Jailbroken: How Does LLM Safety Training Fail?}, 
      author={Alexander Wei and Nika Haghtalab and Jacob Steinhardt},
      year={2023},
      eprint={2307.02483},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{ball_understanding_2024,
      title={Understanding Jailbreak Success: A Study of Latent Space Dynamics in Large Language Models}, 
      author={Sarah Ball and Frauke Kreuter and Nina Panickssery},
      year={2024},
      eprint={2406.09289},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@article{lee_mechanistic_2024,
      title={A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity}, 
      author={Andrew Lee and Xiaoyan Bai and Itamar Pres and Martin Wattenberg and Jonathan K. Kummerfeld and Rada Mihalcea},
      year={2024},
      eprint={2401.01967},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@article{guo_mechanistic_2024,
      title={Mechanistic Unlearning: Robust Knowledge Unlearning and Editing via Mechanistic Localization}, 
      author={Phillip Guo and Aaquib Syed and Abhay Sheshadri and Aidan Ewart and Gintare Karolina Dziugaite},
      year={2024},
      eprint={2410.12949},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{xhonneux_incontext_2024,
      title={In-Context Learning Can Re-learn Forbidden Tasks}, 
      author={Sophie Xhonneux and David Dobre and Jian Tang and Gauthier Gidel and Dhanya Sridhar},
      year={2024},
      eprint={2402.05723},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{mordvintsev_inceptionism_2015,
  author = {Alexander Mordvintsev, Christopher Olah, Mike Tyka},
  year = {2015},
  title = {Inceptionism: Going Deeper into Neural Networks},
  journal = {Google Research Blog}
}

@article{hasting_introduction_2024,
  author = {Sarah Hastings-Woodhouse},
  title = {Introduction to Mechanistic Interpretability},
  year = {2024},
}

@article{lambert_illustrating_2022,
  author = {Lambert, Nathan and Castricato, Louis and von Werra, Leandro and Havrilla, Alex},
  title = {Illustrating Reinforcement Learning from Human Feedback (RLHF)},
  journal = {Hugging Face Blog},
  year = {2022},
  note = {https://huggingface.co/blog/rlhf},
}

@article{bai_constitutional_2022,
	title = {Constitutional {AI}: Harmlessness from {AI} Feedback},
	shorttitle = {Constitutional {AI}},
	abstract = {As {AI} systems become more capable, we would like to enlist their help to supervise other {AIs}. We experiment with methods for training a harmless {AI} assistant through selfimprovement, without any human labels identifying harmful outputs. The only human oversight is provided through a list of rules or principles, and so we refer to the method as ‘Constitutional {AI}’. The process involves both a supervised learning and a reinforcement learning phase. In the supervised phase we sample from an initial model, then generate self-critiques and revisions, and then ﬁnetune the original model on revised responses. In the {RL} phase, we sample from the ﬁnetuned model, use a model to evaluate which of the two samples is better, and then train a preference model from this dataset of {AI} preferences. We then train with {RL} using the preference model as the reward signal, i.e. we use ‘{RL} from {AI} Feedback’ ({RLAIF}). As a result we are able to train a harmless but nonevasive {AI} assistant that engages with harmful queries by explaining its objections to them. Both the {SL} and {RL} methods can leverage chain-of-thought style reasoning to improve the human-judged performance and transparency of {AI} decision making. These methods make it possible to control {AI} behavior more precisely and with far fewer human labels.},
	number = {{arXiv}:2212.08073},
	publisher = {{arXiv}},
	author = {Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and {McKinnon}, Cameron and Chen, Carol and Olsson, Catherine and Olah, Christopher and Hernandez, Danny and Drain, Dawn and Ganguli, Deep and Li, Dustin and Tran-Johnson, Eli and Perez, Ethan and Kerr, Jamie and Mueller, Jared and Ladish, Jeffrey and Landau, Joshua and Ndousse, Kamal and Lukosuite, Kamile and Lovitt, Liane and Sellitto, Michael and Elhage, Nelson and Schiefer, Nicholas and Mercado, Noemi and {DasSarma}, Nova and Lasenby, Robert and Larson, Robin and Ringer, Sam and Johnston, Scott and Kravec, Shauna and Showk, Sheer El and Fort, Stanislav and Lanham, Tamera and Telleen-Lawton, Timothy and Conerly, Tom and Henighan, Tom and Hume, Tristan and Bowman, Samuel R. and Hatfield-Dodds, Zac and Mann, Ben and Amodei, Dario and Joseph, Nicholas and {McCandlish}, Sam and Brown, Tom and Kaplan, Jared},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2212.08073 [cs]},
	keywords = {llm, rlhf, safety},
}

@article{nanda_emergent_2023,
      title={Emergent Linear Representations in World Models of Self-Supervised Sequence Models}, 
      author={Neel Nanda and Andrew Lee and Martin Wattenberg},
      year={2023},
      eprint={2309.00941},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{park_linear_2024,
      title={The Linear Representation Hypothesis and the Geometry of Large Language Models}, 
      author={Kiho Park and Yo Joong Choe and Victor Veitch},
      year={2024},
      eprint={2311.03658},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}


@article{casper_openproblems_2023,
      title={Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback}, 
      author={Stephen Casper and Xander Davies and Claudia Shi and Thomas Krendl Gilbert and Jérémy Scheurer and Javier Rando and Rachel Freedman and Tomasz Korbak and David Lindner and Pedro Freire and Tony Wang and Samuel Marks and Charbel-Raphaël Segerie and Micah Carroll and Andi Peng and Phillip Christoffersen and Mehul Damani and Stewart Slocum and Usman Anwar and Anand Siththaranjan and Max Nadeau and Eric J. Michaud and Jacob Pfau and Dmitrii Krasheninnikov and Xin Chen and Lauro Langosco and Peter Hase and Erdem Bıyık and Anca Dragan and David Krueger and Dorsa Sadigh and Dylan Hadfield-Menell},
      year={2023},
      eprint={2307.15217},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
}

@article{elhage_superposition_2022,
   title={Toy Models of Superposition},
   author={Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Schiefer, Nicholas and Henighan, Tom and Kravec, Shauna and Hatfield-Dodds, Zac and Lasenby, Robert and Drain, Dawn and Chen, Carol and Grosse, Roger and McCandlish, Sam and Kaplan, Jared and Amodei, Dario and Wattenberg, Martin and Olah, Christopher},
   year={2022},
   journal={Transformer Circuits Thread},
   note={https://transformer-circuits.pub/2022/toy_model/index.html}
}

@article{olah_zoom_2020,
  author = {Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
  title = {Zoom In: An Introduction to Circuits},
  journal = {Distill},
  year = {2020},
  note = {https://distill.pub/2020/circuits/zoom-in},
  doi = {10.23915/distill.00024.001}
}

@article{olah_overview_2020,
  author = {Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
  title = {An Overview of Early Vision in InceptionV1},
  journal = {Distill},
  year = {2020},
  note = {https://distill.pub/2020/circuits/early-vision},
  doi = {10.23915/distill.00024.002}
}

@article{jiang_discrete_2019,
	author = {Jiang, Rundong and Li, Ming and Tang, Shiming},
	title = {Discrete neural clusters encode orientation, curvature and corners in macaque V4},
	year = {2019},
	doi = {10.1101/808907},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {As an intermediate stage of the ventral visual pathway, V4 plays a crucial role in transforming basic orientation information into higher-ordered object representations. However, the neural mechanisms underlying the encoding of simple, complex and intermediate features in V4 remain poorly understood. Using two-photon calcium imaging in awake macaques, we recorded the responses of large populations of V4 neurons to thousands of natural images. To understand these high-dimensional data sets, we performed dimensional reduction analysis on the neuronal population responses. We found orthogonal dimensions encoding orientation and more complex features, with curves and corners represented separately. These distinct feature dimensions were encoded by spatially clustered subpopulations of neurons organized in iso-orientation and curvature domains. Using synthetic stimuli, we confirmed that curvature and corner selective neurons in V4 were tuned to integral features rather than combinations of local orientation compartments. Our results show that curves and corners are encoded by neurons clustered into functional domains separate from orientation. This functionally specific population architecture may serve to facilitate local computations that expedite more complex shape and object representations at higher levels of the ventral pathway.},
	journal = {bioRxiv}
}

@article{nanda_comprehensive_2022, 
  title={A Comprehensive Mechanistic Interpretability Explainer & Glossary}, 
  author={Nanda, Neel}, 
  year={2022}, 
  month={Dec}
}

@article{mikolov_efficient_2013,
      title={Efficient Estimation of Word Representations in Vector Space}, 
      author={Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
      year={2013},
      eprint={1301.3781},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@article{socher_zeroshot_2013,
      title={Zero-Shot Learning Through Cross-Modal Transfer}, 
      author={Richard Socher and Milind Ganjoo and Hamsa Sridhar and Osbert Bastani and Christopher D. Manning and Andrew Y. Ng},
      year={2013},
      eprint={1301.3666},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
}



@article{zou_representation_2023,
      title={Representation Engineering: A Top-Down Approach to AI Transparency}, 
      author={Andy Zou and Long Phan and Sarah Chen and James Campbell and Phillip Guo and Richard Ren and Alexander Pan and Xuwang Yin and Mantas Mazeika and Ann-Kathrin Dombrowski and Shashwat Goel and Nathaniel Li and Michael J. Byun and Zifan Wang and Alex Mallen and Steven Basart and Sanmi Koyejo and Dawn Song and Matt Fredrikson and J. Zico Kolter and Dan Hendrycks},
      year={2023},
      eprint={2310.01405},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}


@article{nanda_transformerlens_2022,
    title = {TransformerLens},
    author = {Neel Nanda and Joseph Bloom},
    year = {2022},
}

@article{bloom_sae_2024,
   title = {SAELens},
   author = {Joseph Bloom and David Chanin},
   year = {2024},
}


@article{bereska_mechanistic_2024,
      title={Mechanistic Interpretability for AI Safety -- A Review}, 
      author={Leonard Bereska and Efstratios Gavves},
      year={2024},
      eprint={2404.14082},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
}

@article{hayase_query_2024,
      title={Query-Based Adversarial Prompt Generation}, 
      author={Jonathan Hayase and Ema Borevkovic and Nicholas Carlini and Florian Tramèr and Milad Nasr},
      year={2024},
      eprint={2402.12329},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@article{ebrahimi_hotflip_2017,
      title = {HotFlip: White-Box Adversarial Examples for Text Classification},
      author={Javid Ebrahimi, Anyi Rao, Daniel Lowd, Dejing Dou},
      year={2017},
      eprint={1712.06751},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}


@misc{haize_sota_2024,
      title={Making a SOTA Adversarial Attack on LLMs 38x Faster},
      author={Haize},
      year={2024},
}

@article{peng_interpreting_2024,
      title={Interpreting the Curse of Dimensionality from Distance Concentration and Manifold Effect}, 
      author={Dehua Peng and Zhipeng Gui and Huayi Wu},
      year={2024},
      eprint={2401.00422},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}
@article{he_jailbreaklens_2024,
      title={JailbreakLens: Interpreting Jailbreak Mechanism in the Lens of Representation and Circuit}, 
      author={Zeqing He and Zhibo Wang and Zhixuan Chu and Huiyu Xu and Rui Zheng and Kui Ren and Chun Chen},
      year={2024},
      eprint={2411.11114},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
}


@misc{wang_attngcg_2024,
      title={AttnGCG: Enhancing Jailbreaking Attacks on LLMs with Attention Manipulation}, 
      author={Zijun Wang and Haoqin Tu and Jieru Mei and Bingchen Zhao and Yisen Wang and Cihang Xie},
      year={2024},
      eprint={2410.09040},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@article{liao_amplegcg_2024,
  title={AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs},
  author={Liao, Zeyi and Sun, Huan},
  journal={arXiv preprint arXiv:2404.07921},
  year={2024}
}

@article{kumar_amplegcg_2024,
  title={AmpleGCG-Plus: A Strong Generative Model of Adversarial Suffixes to Jailbreak LLMs with Higher Success Rates in Fewer Attempts},
  author={Kumar, Vishal and Liao, Zeyi and Jones, Jaylen and Sun, Huan},
  journal={arXiv preprint arXiv:2410.22143},
  year={2024}
}

@misc{jia_improved_2024,
      title={Improved Techniques for Optimization-Based Jailbreaking on Large Language Models}, 
      author={Xiaojun Jia and Tianyu Pang and Chao Du and Yihao Huang and Jindong Gu and Yang Liu and Xiaochun Cao and Min Lin},
      year={2024},
      eprint={2405.21018},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@misc{zhou_alignment_2024,
      title={How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States}, 
      author={Zhenhong Zhou and Haiyang Yu and Xinghua Zhang and Rongwu Xu and Fei Huang and Yongbin Li},
      year={2024},
      eprint={2406.05644},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}


@misc{panickssery_steering_2024,
      title={Steering Llama 2 via Contrastive Activation Addition}, 
      author={Nina Panickssery and Nick Gabrieli and Julian Schulz and Meg Tong and Evan Hubinger and Alexander Matt Turner},
      year={2024},
      eprint={2312.06681},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@misc{wang_trojan_2024,
      title={Trojan Activation Attack: Red-Teaming Large Language Models using Activation Steering for Safety-Alignment}, 
      author={Haoran Wang and Kai Shu},
      year={2024},
      eprint={2311.09433},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
}

@article{zhao_unleashing_2024,
      title={Unleashing the Unseen: Harnessing Benign Datasets for Jailbreaking Large Language Models}, 
      author={Wei Zhao and Zhe Li and Yige Li and Jun Sun},
      year={2024},
      eprint={2410.00451},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
}

@article{lin_understanding_2024,
      title={Towards Understanding Jailbreak Attacks in LLMs: A Representation Space Analysis}, 
      author={Yuping Lin and Pengfei He and Han Xu and Yue Xing and Makoto Yamada and Hui Liu and Jiliang Tang},
      year={2024},
      eprint={2406.10794},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@misc{wolf_huggingface_2020,
      title={HuggingFace's Transformers: State-of-the-art Natural Language Processing}, 
      author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
      year={2020},
      eprint={1910.03771},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@article{marks_geometry_2024,
      title={The Geometry of Truth: Emergent Linear Structure in Large Language Model Representations of True/False Datasets}, 
      author={Samuel Marks and Max Tegmark},
      year={2024},
      eprint={2310.06824},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
}

@article{engels_language_2024,
      title={Not All Language Model Features Are Linear}, 
      author={Joshua Engels and Eric J. Michaud and Isaac Liao and Wes Gurnee and Max Tegmark},
      year={2024},
      eprint={2405.14860},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@misc{haize_agc_2024,
  title={Making a SOTA Adversarial Attack on LLMs 38x Faster},
  year={2024},
  author={Haize Lab},
}


@online{straznickas_takeaways_2024,
  author = {Straznickas, Zygimantas and Thompson, T. Ben and Sklar,
    Michael},
  title = {Takeaways from the {NeurIPS} 2023 {Trojan} {Detection}
    {Competition}},
  date = {2024-01-13},
  langid = {en}
}

@article{asadi_alternative_2017,
      title={An Alternative Softmax Operator for Reinforcement Learning}, 
      author={Kavosh Asadi and Michael L. Littman},
      year={2017},
      eprint={1612.05628},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
}
@article{zhao_accelerating_2024,
      title={Accelerating Greedy Coordinate Gradient and General Prompt Optimization via Probe Sampling}, 
      author={Yiran Zhao and Wenyue Zheng and Tianle Cai and Xuan Long Do and Kenji Kawaguchi and Anirudh Goyal and Michael Shieh},
      year={2024},
      eprint={2403.01251},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@misc{grayswan_nanogcg_2024,
  title={nanoGCG: A fast and lightweight open source implementation of GCG},
  year={2024},
}

@misc{logit_lens_2020,
  title={interpreting GPT: the logit lens},
  author={nostalgebraist},
  year={2020},
}

@article{templeton_scaling_2024,
   title={Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet},
   author={Templeton, Adly and Conerly, Tom and Marcus, Jonathan and Lindsey, Jack and Bricken, Trenton and Chen, Brian and Pearce, Adam and Citro, Craig and Ameisen, Emmanuel and Jones, Andy and Cunningham, Hoagy and Turner, Nicholas L and McDougall, Callum and MacDiarmid, Monte and Freeman, C. Daniel and Sumers, Theodore R. and Rees, Edward and Batson, Joshua and Jermyn, Adam and Carter, Shan and Olah, Chris and Henighan, Tom},
   year={2024},
   journal={Transformer Circuits Thread},
}



@misc{llama3.2,
  title = {Llama 3.2: Revolutionizing edge AI and vision with open, customizable models},
  author = {AI @ Meta},
  month = {September},
  year = {2024}
}

@misc{qwenteam_qwen25_2025,
      title={Qwen2.5 Technical Report}, 
      author={Qwen and : and An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tianyi Tang and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
      year={2025},
      eprint={2412.15115},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@misc{gemmateam_gemma2_2024,
      title={Gemma 2: Improving Open Language Models at a Practical Size}, 
      author={Gemma Team and Morgane Riviere and Shreya Pathak and Pier Giuseppe Sessa and Cassidy Hardin and Surya Bhupatiraju and Léonard Hussenot and Thomas Mesnard and Bobak Shahriari and Alexandre Ramé and Johan Ferret and Peter Liu and Pouya Tafti and Abe Friesen and Michelle Casbon and Sabela Ramos and Ravin Kumar and Charline Le Lan and Sammy Jerome and Anton Tsitsulin and Nino Vieillard and Piotr Stanczyk and Sertan Girgin and Nikola Momchev and Matt Hoffman and Shantanu Thakoor and Jean-Bastien Grill and Behnam Neyshabur and Olivier Bachem and Alanna Walton and Aliaksei Severyn and Alicia Parrish and Aliya Ahmad and Allen Hutchison and Alvin Abdagic and Amanda Carl and Amy Shen and Andy Brock and Andy Coenen and Anthony Laforge and Antonia Paterson and Ben Bastian and Bilal Piot and Bo Wu and Brandon Royal and Charlie Chen and Chintu Kumar and Chris Perry and Chris Welty and Christopher A. Choquette-Choo and Danila Sinopalnikov and David Weinberger and Dimple Vijaykumar and Dominika Rogozińska and Dustin Herbison and Elisa Bandy and Emma Wang and Eric Noland and Erica Moreira and Evan Senter and Evgenii Eltyshev and Francesco Visin and Gabriel Rasskin and Gary Wei and Glenn Cameron and Gus Martins and Hadi Hashemi and Hanna Klimczak-Plucińska and Harleen Batra and Harsh Dhand and Ivan Nardini and Jacinda Mein and Jack Zhou and James Svensson and Jeff Stanway and Jetha Chan and Jin Peng Zhou and Joana Carrasqueira and Joana Iljazi and Jocelyn Becker and Joe Fernandez and Joost van Amersfoort and Josh Gordon and Josh Lipschultz and Josh Newlan and Ju-yeong Ji and Kareem Mohamed and Kartikeya Badola and Kat Black and Katie Millican and Keelin McDonell and Kelvin Nguyen and Kiranbir Sodhia and Kish Greene and Lars Lowe Sjoesund and Lauren Usui and Laurent Sifre and Lena Heuermann and Leticia Lago and Lilly McNealus and Livio Baldini Soares and Logan Kilpatrick and Lucas Dixon and Luciano Martins and Machel Reid and Manvinder Singh and Mark Iverson and Martin Görner and Mat Velloso and Mateo Wirth and Matt Davidow and Matt Miller and Matthew Rahtz and Matthew Watson and Meg Risdal and Mehran Kazemi and Michael Moynihan and Ming Zhang and Minsuk Kahng and Minwoo Park and Mofi Rahman and Mohit Khatwani and Natalie Dao and Nenshad Bardoliwalla and Nesh Devanathan and Neta Dumai and Nilay Chauhan and Oscar Wahltinez and Pankil Botarda and Parker Barnes and Paul Barham and Paul Michel and Pengchong Jin and Petko Georgiev and Phil Culliton and Pradeep Kuppala and Ramona Comanescu and Ramona Merhej and Reena Jana and Reza Ardeshir Rokni and Rishabh Agarwal and Ryan Mullins and Samaneh Saadat and Sara Mc Carthy and Sarah Cogan and Sarah Perrin and Sébastien M. R. Arnold and Sebastian Krause and Shengyang Dai and Shruti Garg and Shruti Sheth and Sue Ronstrom and Susan Chan and Timothy Jordan and Ting Yu and Tom Eccles and Tom Hennigan and Tomas Kocisky and Tulsee Doshi and Vihan Jain and Vikas Yadav and Vilobh Meshram and Vishal Dharmadhikari and Warren Barkley and Wei Wei and Wenming Ye and Woohyun Han and Woosuk Kwon and Xiang Xu and Zhe Shen and Zhitao Gong and Zichuan Wei and Victor Cotruta and Phoebe Kirk and Anand Rao and Minh Giang and Ludovic Peran and Tris Warkentin and Eli Collins and Joelle Barral and Zoubin Ghahramani and Raia Hadsell and D. Sculley and Jeanine Banks and Anca Dragan and Slav Petrov and Oriol Vinyals and Jeff Dean and Demis Hassabis and Koray Kavukcuoglu and Clement Farabet and Elena Buchatskaya and Sebastian Borgeaud and Noah Fiedel and Armand Joulin and Kathleen Kenealy and Robert Dadashi and Alek Andreev},
      year={2024},
      eprint={2408.00118},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@misc{ministraux, 
  title= {Un Ministral, des Ministraux}, 
  year = {2024}, 
  month = {October},
  author={Mistral Team},
}

@misc{mistral_small,
  year = {2025}, 
  month = {January},
  title = {Mistral Small}, 
  author = {Mistral Team},
}

@article{li_safety_2024,
      title={Safety Layers in Aligned Large Language Models: The Key to LLM Security}, 
      author={Shen Li and Liuyi Yao and Lan Zhang and Yaliang Li},
      year={2024},
      eprint={2408.17003},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
}

@article{zhao_causality_2023,
      title={Causality Analysis for Evaluating the Security of Large Language Models}, 
      author={Wei Zhao and Zhe Li and Jun Sun},
      year={2023},
      eprint={2312.07876},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
}

@article{chen_finding_2024,
      title={Finding Safety Neurons in Large Language Models}, 
      author={Jianhui Chen and Xiaozhi Wang and Zijun Yao and Yushi Bai and Lei Hou and Juanzi Li},
      year={2024},
      eprint={2406.14144},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@article{marks_sparse_2024,
      title={Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models}, 
      author={Samuel Marks and Can Rager and Eric J. Michaud and Yonatan Belinkov and David Bau and Aaron Mueller},
      year={2024},
      eprint={2403.19647},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@misc{geminiteam_gemini15_2024,
      title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context}, 
      author={Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and Libin Bai and Anmol Gulati and Garrett Tanzer and Damien Vincent and Zhufeng Pan and Shibo Wang and Soroosh Mariooryad and Yifan Ding and Xinyang Geng and Fred Alcober and Roy Frostig and Mark Omernick and Lexi Walker and Cosmin Paduraru and Christina Sorokin and Andrea Tacchetti and Colin Gaffney and Samira Daruki and Olcan Sercinoglu and Zach Gleicher and Juliette Love and Paul Voigtlaender and Rohan Jain and Gabriela Surita and Kareem Mohamed and Rory Blevins and Junwhan Ahn and Tao Zhu and Kornraphop Kawintiranon and Orhan Firat and Yiming Gu and Yujing Zhang and Matthew Rahtz and Manaal Faruqui and Natalie Clay and Justin Gilmer and JD Co-Reyes and Ivo Penchev and Rui Zhu and Nobuyuki Morioka and Kevin Hui and Krishna Haridasan and Victor Campos and Mahdis Mahdieh and Mandy Guo and Samer Hassan and Kevin Kilgour and Arpi Vezer and Heng-Tze Cheng and Raoul de Liedekerke and Siddharth Goyal and Paul Barham and DJ Strouse and Seb Noury and Jonas Adler and Mukund Sundararajan and Sharad Vikram and Dmitry Lepikhin and Michela Paganini and Xavier Garcia and Fan Yang and Dasha Valter and Maja Trebacz and Kiran Vodrahalli and Chulayuth Asawaroengchai and Roman Ring and Norbert Kalb and Livio Baldini Soares and Siddhartha Brahma and David Steiner and Tianhe Yu and Fabian Mentzer and Antoine He and Lucas Gonzalez and Bibo Xu and Raphael Lopez Kaufman and Laurent El Shafey and Junhyuk Oh and Tom Hennigan and George van den Driessche and Seth Odoom and Mario Lucic and Becca Roelofs and Sid Lall and Amit Marathe and Betty Chan and Santiago Ontanon and Luheng He and Denis Teplyashin and Jonathan Lai and Phil Crone and Bogdan Damoc and Lewis Ho and Sebastian Riedel and Karel Lenc and Chih-Kuan Yeh and Aakanksha Chowdhery and Yang Xu and Mehran Kazemi and Ehsan Amid and Anastasia Petrushkina and Kevin Swersky and Ali Khodaei and Gowoon Chen and Chris Larkin and Mario Pinto and Geng Yan and Adria Puigdomenech Badia and Piyush Patil and Steven Hansen and Dave Orr and Sebastien M. R. Arnold and Jordan Grimstad and Andrew Dai and Sholto Douglas and Rishika Sinha and Vikas Yadav and Xi Chen and Elena Gribovskaya and Jacob Austin and Jeffrey Zhao and Kaushal Patel and Paul Komarek and Sophia Austin and Sebastian Borgeaud and Linda Friso and Abhimanyu Goyal and Ben Caine and Kris Cao and Da-Woon Chung and Matthew Lamm and Gabe Barth-Maron and Thais Kagohara and Kate Olszewska and Mia Chen and Kaushik Shivakumar and Rishabh Agarwal and Harshal Godhia and Ravi Rajwar and Javier Snaider and Xerxes Dotiwalla and Yuan Liu and Aditya Barua and Victor Ungureanu and Yuan Zhang and Bat-Orgil Batsaikhan and Mateo Wirth and James Qin and Ivo Danihelka and Tulsee Doshi and Martin Chadwick and Jilin Chen and Sanil Jain and Quoc Le and Arjun Kar and Madhu Gurumurthy and Cheng Li and Ruoxin Sang and Fangyu Liu and Lampros Lamprou and Rich Munoz and Nathan Lintz and Harsh Mehta and Heidi Howard and Malcolm Reynolds and Lora Aroyo and Quan Wang and Lorenzo Blanco and Albin Cassirer and Jordan Griffith and Dipanjan Das and Stephan Lee and Jakub Sygnowski and Zach Fisher and James Besley and Richard Powell and Zafarali Ahmed and Dominik Paulus and David Reitter and Zalan Borsos and Rishabh Joshi and Aedan Pope and Steven Hand and Vittorio Selo and Vihan Jain and Nikhil Sethi and Megha Goel and Takaki Makino and Rhys May and Zhen Yang and Johan Schalkwyk and Christina Butterfield and Anja Hauth and Alex Goldin and Will Hawkins and Evan Senter and Sergey Brin and Oliver Woodman and Marvin Ritter and Eric Noland and Minh Giang and Vijay Bolina and Lisa Lee and Tim Blyth and Ian Mackinnon and Machel Reid and Obaid Sarvana and David Silver and Alexander Chen and Lily Wang and Loren Maggiore and Oscar Chang and Nithya Attaluri and Gregory Thornton and Chung-Cheng Chiu and Oskar Bunyan and Nir Levine and Timothy Chung and Evgenii Eltyshev and Xiance Si and Timothy Lillicrap and Demetra Brady and Vaibhav Aggarwal and Boxi Wu and Yuanzhong Xu and Ross McIlroy and Kartikeya Badola and Paramjit Sandhu and Erica Moreira and Wojciech Stokowiec and Ross Hemsley and Dong Li and Alex Tudor and Pranav Shyam and Elahe Rahimtoroghi and Salem Haykal and Pablo Sprechmann and Xiang Zhou and Diana Mincu and Yujia Li and Ravi Addanki and Kalpesh Krishna and Xiao Wu and Alexandre Frechette and Matan Eyal and Allan Dafoe and Dave Lacey and Jay Whang and Thi Avrahami and Ye Zhang and Emanuel Taropa and Hanzhao Lin and Daniel Toyama and Eliza Rutherford and Motoki Sano and HyunJeong Choe and Alex Tomala and Chalence Safranek-Shrader and Nora Kassner and Mantas Pajarskas and Matt Harvey and Sean Sechrist and Meire Fortunato and Christina Lyu and Gamaleldin Elsayed and Chenkai Kuang and James Lottes and Eric Chu and Chao Jia and Chih-Wei Chen and Peter Humphreys and Kate Baumli and Connie Tao and Rajkumar Samuel and Cicero Nogueira dos Santos and Anders Andreassen and Nemanja Rakićević and Dominik Grewe and Aviral Kumar and Stephanie Winkler and Jonathan Caton and Andrew Brock and Sid Dalmia and Hannah Sheahan and Iain Barr and Yingjie Miao and Paul Natsev and Jacob Devlin and Feryal Behbahani and Flavien Prost and Yanhua Sun and Artiom Myaskovsky and Thanumalayan Sankaranarayana Pillai and Dan Hurt and Angeliki Lazaridou and Xi Xiong and Ce Zheng and Fabio Pardo and Xiaowei Li and Dan Horgan and Joe Stanton and Moran Ambar and Fei Xia and Alejandro Lince and Mingqiu Wang and Basil Mustafa and Albert Webson and Hyo Lee and Rohan Anil and Martin Wicke and Timothy Dozat and Abhishek Sinha and Enrique Piqueras and Elahe Dabir and Shyam Upadhyay and Anudhyan Boral and Lisa Anne Hendricks and Corey Fry and Josip Djolonga and Yi Su and Jake Walker and Jane Labanowski and Ronny Huang and Vedant Misra and Jeremy Chen and RJ Skerry-Ryan and Avi Singh and Shruti Rijhwani and Dian Yu and Alex Castro-Ros and Beer Changpinyo and Romina Datta and Sumit Bagri and Arnar Mar Hrafnkelsson and Marcello Maggioni and Daniel Zheng and Yury Sulsky and Shaobo Hou and Tom Le Paine and Antoine Yang and Jason Riesa and Dominika Rogozinska and Dror Marcus and Dalia El Badawy and Qiao Zhang and Luyu Wang and Helen Miller and Jeremy Greer and Lars Lowe Sjos and Azade Nova and Heiga Zen and Rahma Chaabouni and Mihaela Rosca and Jiepu Jiang and Charlie Chen and Ruibo Liu and Tara Sainath and Maxim Krikun and Alex Polozov and Jean-Baptiste Lespiau and Josh Newlan and Zeyncep Cankara and Soo Kwak and Yunhan Xu and Phil Chen and Andy Coenen and Clemens Meyer and Katerina Tsihlas and Ada Ma and Juraj Gottweis and Jinwei Xing and Chenjie Gu and Jin Miao and Christian Frank and Zeynep Cankara and Sanjay Ganapathy and Ishita Dasgupta and Steph Hughes-Fitt and Heng Chen and David Reid and Keran Rong and Hongmin Fan and Joost van Amersfoort and Vincent Zhuang and Aaron Cohen and Shixiang Shane Gu and Anhad Mohananey and Anastasija Ilic and Taylor Tobin and John Wieting and Anna Bortsova and Phoebe Thacker and Emma Wang and Emily Caveness and Justin Chiu and Eren Sezener and Alex Kaskasoli and Steven Baker and Katie Millican and Mohamed Elhawaty and Kostas Aisopos and Carl Lebsack and Nathan Byrd and Hanjun Dai and Wenhao Jia and Matthew Wiethoff and Elnaz Davoodi and Albert Weston and Lakshman Yagati and Arun Ahuja and Isabel Gao and Golan Pundak and Susan Zhang and Michael Azzam and Khe Chai Sim and Sergi Caelles and James Keeling and Abhanshu Sharma and Andy Swing and YaGuang Li and Chenxi Liu and Carrie Grimes Bostock and Yamini Bansal and Zachary Nado and Ankesh Anand and Josh Lipschultz and Abhijit Karmarkar and Lev Proleev and Abe Ittycheriah and Soheil Hassas Yeganeh and George Polovets and Aleksandra Faust and Jiao Sun and Alban Rrustemi and Pen Li and Rakesh Shivanna and Jeremiah Liu and Chris Welty and Federico Lebron and Anirudh Baddepudi and Sebastian Krause and Emilio Parisotto and Radu Soricut and Zheng Xu and Dawn Bloxwich and Melvin Johnson and Behnam Neyshabur and Justin Mao-Jones and Renshen Wang and Vinay Ramasesh and Zaheer Abbas and Arthur Guez and Constant Segal and Duc Dung Nguyen and James Svensson and Le Hou and Sarah York and Kieran Milan and Sophie Bridgers and Wiktor Gworek and Marco Tagliasacchi and James Lee-Thorp and Michael Chang and Alexey Guseynov and Ale Jakse Hartman and Michael Kwong and Ruizhe Zhao and Sheleem Kashem and Elizabeth Cole and Antoine Miech and Richard Tanburn and Mary Phuong and Filip Pavetic and Sebastien Cevey and Ramona Comanescu and Richard Ives and Sherry Yang and Cosmo Du and Bo Li and Zizhao Zhang and Mariko Iinuma and Clara Huiyi Hu and Aurko Roy and Shaan Bijwadia and Zhenkai Zhu and Danilo Martins and Rachel Saputro and Anita Gergely and Steven Zheng and Dawei Jia and Ioannis Antonoglou and Adam Sadovsky and Shane Gu and Yingying Bi and Alek Andreev and Sina Samangooei and Mina Khan and Tomas Kocisky and Angelos Filos and Chintu Kumar and Colton Bishop and Adams Yu and Sarah Hodkinson and Sid Mittal and Premal Shah and Alexandre Moufarek and Yong Cheng and Adam Bloniarz and Jaehoon Lee and Pedram Pejman and Paul Michel and Stephen Spencer and Vladimir Feinberg and Xuehan Xiong and Nikolay Savinov and Charlotte Smith and Siamak Shakeri and Dustin Tran and Mary Chesus and Bernd Bohnet and George Tucker and Tamara von Glehn and Carrie Muir and Yiran Mao and Hideto Kazawa and Ambrose Slone and Kedar Soparkar and Disha Shrivastava and James Cobon-Kerr and Michael Sharman and Jay Pavagadhi and Carlos Araya and Karolis Misiunas and Nimesh Ghelani and Michael Laskin and David Barker and Qiujia Li and Anton Briukhov and Neil Houlsby and Mia Glaese and Balaji Lakshminarayanan and Nathan Schucher and Yunhao Tang and Eli Collins and Hyeontaek Lim and Fangxiaoyu Feng and Adria Recasens and Guangda Lai and Alberto Magni and Nicola De Cao and Aditya Siddhant and Zoe Ashwood and Jordi Orbay and Mostafa Dehghani and Jenny Brennan and Yifan He and Kelvin Xu and Yang Gao and Carl Saroufim and James Molloy and Xinyi Wu and Seb Arnold and Solomon Chang and Julian Schrittwieser and Elena Buchatskaya and Soroush Radpour and Martin Polacek and Skye Giordano and Ankur Bapna and Simon Tokumine and Vincent Hellendoorn and Thibault Sottiaux and Sarah Cogan and Aliaksei Severyn and Mohammad Saleh and Shantanu Thakoor and Laurent Shefey and Siyuan Qiao and Meenu Gaba and Shuo-yiin Chang and Craig Swanson and Biao Zhang and Benjamin Lee and Paul Kishan Rubenstein and Gan Song and Tom Kwiatkowski and Anna Koop and Ajay Kannan and David Kao and Parker Schuh and Axel Stjerngren and Golnaz Ghiasi and Gena Gibson and Luke Vilnis and Ye Yuan and Felipe Tiengo Ferreira and Aishwarya Kamath and Ted Klimenko and Ken Franko and Kefan Xiao and Indro Bhattacharya and Miteyan Patel and Rui Wang and Alex Morris and Robin Strudel and Vivek Sharma and Peter Choy and Sayed Hadi Hashemi and Jessica Landon and Mara Finkelstein and Priya Jhakra and Justin Frye and Megan Barnes and Matthew Mauger and Dennis Daun and Khuslen Baatarsukh and Matthew Tung and Wael Farhan and Henryk Michalewski and Fabio Viola and Felix de Chaumont Quitry and Charline Le Lan and Tom Hudson and Qingze Wang and Felix Fischer and Ivy Zheng and Elspeth White and Anca Dragan and Jean-baptiste Alayrac and Eric Ni and Alexander Pritzel and Adam Iwanicki and Michael Isard and Anna Bulanova and Lukas Zilka and Ethan Dyer and Devendra Sachan and Srivatsan Srinivasan and Hannah Muckenhirn and Honglong Cai and Amol Mandhane and Mukarram Tariq and Jack W. Rae and Gary Wang and Kareem Ayoub and Nicholas FitzGerald and Yao Zhao and Woohyun Han and Chris Alberti and Dan Garrette and Kashyap Krishnakumar and Mai Gimenez and Anselm Levskaya and Daniel Sohn and Josip Matak and Inaki Iturrate and Michael B. Chang and Jackie Xiang and Yuan Cao and Nishant Ranka and Geoff Brown and Adrian Hutter and Vahab Mirrokni and Nanxin Chen and Kaisheng Yao and Zoltan Egyed and Francois Galilee and Tyler Liechty and Praveen Kallakuri and Evan Palmer and Sanjay Ghemawat and Jasmine Liu and David Tao and Chloe Thornton and Tim Green and Mimi Jasarevic and Sharon Lin and Victor Cotruta and Yi-Xuan Tan and Noah Fiedel and Hongkun Yu and Ed Chi and Alexander Neitz and Jens Heitkaemper and Anu Sinha and Denny Zhou and Yi Sun and Charbel Kaed and Brice Hulse and Swaroop Mishra and Maria Georgaki and Sneha Kudugunta and Clement Farabet and Izhak Shafran and Daniel Vlasic and Anton Tsitsulin and Rajagopal Ananthanarayanan and Alen Carin and Guolong Su and Pei Sun and Shashank V and Gabriel Carvajal and Josef Broder and Iulia Comsa and Alena Repina and William Wong and Warren Weilun Chen and Peter Hawkins and Egor Filonov and Lucia Loher and Christoph Hirnschall and Weiyi Wang and Jingchen Ye and Andrea Burns and Hardie Cate and Diana Gage Wright and Federico Piccinini and Lei Zhang and Chu-Cheng Lin and Ionel Gog and Yana Kulizhskaya and Ashwin Sreevatsa and Shuang Song and Luis C. Cobo and Anand Iyer and Chetan Tekur and Guillermo Garrido and Zhuyun Xiao and Rupert Kemp and Huaixiu Steven Zheng and Hui Li and Ananth Agarwal and Christel Ngani and Kati Goshvadi and Rebeca Santamaria-Fernandez and Wojciech Fica and Xinyun Chen and Chris Gorgolewski and Sean Sun and Roopal Garg and Xinyu Ye and S. M. Ali Eslami and Nan Hua and Jon Simon and Pratik Joshi and Yelin Kim and Ian Tenney and Sahitya Potluri and Lam Nguyen Thiet and Quan Yuan and Florian Luisier and Alexandra Chronopoulou and Salvatore Scellato and Praveen Srinivasan and Minmin Chen and Vinod Koverkathu and Valentin Dalibard and Yaming Xu and Brennan Saeta and Keith Anderson and Thibault Sellam and Nick Fernando and Fantine Huot and Junehyuk Jung and Mani Varadarajan and Michael Quinn and Amit Raul and Maigo Le and Ruslan Habalov and Jon Clark and Komal Jalan and Kalesha Bullard and Achintya Singhal and Thang Luong and Boyu Wang and Sujeevan Rajayogam and Julian Eisenschlos and Johnson Jia and Daniel Finchelstein and Alex Yakubovich and Daniel Balle and Michael Fink and Sameer Agarwal and Jing Li and Dj Dvijotham and Shalini Pal and Kai Kang and Jaclyn Konzelmann and Jennifer Beattie and Olivier Dousse and Diane Wu and Remi Crocker and Chen Elkind and Siddhartha Reddy Jonnalagadda and Jong Lee and Dan Holtmann-Rice and Krystal Kallarackal and Rosanne Liu and Denis Vnukov and Neera Vats and Luca Invernizzi and Mohsen Jafari and Huanjie Zhou and Lilly Taylor and Jennifer Prendki and Marcus Wu and Tom Eccles and Tianqi Liu and Kavya Kopparapu and Francoise Beaufays and Christof Angermueller and Andreea Marzoca and Shourya Sarcar and Hilal Dib and Jeff Stanway and Frank Perbet and Nejc Trdin and Rachel Sterneck and Andrey Khorlin and Dinghua Li and Xihui Wu and Sonam Goenka and David Madras and Sasha Goldshtein and Willi Gierke and Tong Zhou and Yaxin Liu and Yannie Liang and Anais White and Yunjie Li and Shreya Singh and Sanaz Bahargam and Mark Epstein and Sujoy Basu and Li Lao and Adnan Ozturel and Carl Crous and Alex Zhai and Han Lu and Zora Tung and Neeraj Gaur and Alanna Walton and Lucas Dixon and Ming Zhang and Amir Globerson and Grant Uy and Andrew Bolt and Olivia Wiles and Milad Nasr and Ilia Shumailov and Marco Selvi and Francesco Piccinno and Ricardo Aguilar and Sara McCarthy and Misha Khalman and Mrinal Shukla and Vlado Galic and John Carpenter and Kevin Villela and Haibin Zhang and Harry Richardson and James Martens and Matko Bosnjak and Shreyas Rammohan Belle and Jeff Seibert and Mahmoud Alnahlawi and Brian McWilliams and Sankalp Singh and Annie Louis and Wen Ding and Dan Popovici and Lenin Simicich and Laura Knight and Pulkit Mehta and Nishesh Gupta and Chongyang Shi and Saaber Fatehi and Jovana Mitrovic and Alex Grills and Joseph Pagadora and Tsendsuren Munkhdalai and Dessie Petrova and Danielle Eisenbud and Zhishuai Zhang and Damion Yates and Bhavishya Mittal and Nilesh Tripuraneni and Yannis Assael and Thomas Brovelli and Prateek Jain and Mihajlo Velimirovic and Canfer Akbulut and Jiaqi Mu and Wolfgang Macherey and Ravin Kumar and Jun Xu and Haroon Qureshi and Gheorghe Comanici and Jeremy Wiesner and Zhitao Gong and Anton Ruddock and Matthias Bauer and Nick Felt and Anirudh GP and Anurag Arnab and Dustin Zelle and Jonas Rothfuss and Bill Rosgen and Ashish Shenoy and Bryan Seybold and Xinjian Li and Jayaram Mudigonda and Goker Erdogan and Jiawei Xia and Jiri Simsa and Andrea Michi and Yi Yao and Christopher Yew and Steven Kan and Isaac Caswell and Carey Radebaugh and Andre Elisseeff and Pedro Valenzuela and Kay McKinney and Kim Paterson and Albert Cui and Eri Latorre-Chimoto and Solomon Kim and William Zeng and Ken Durden and Priya Ponnapalli and Tiberiu Sosea and Christopher A. Choquette-Choo and James Manyika and Brona Robenek and Harsha Vashisht and Sebastien Pereira and Hoi Lam and Marko Velic and Denese Owusu-Afriyie and Katherine Lee and Tolga Bolukbasi and Alicia Parrish and Shawn Lu and Jane Park and Balaji Venkatraman and Alice Talbert and Lambert Rosique and Yuchung Cheng and Andrei Sozanschi and Adam Paszke and Praveen Kumar and Jessica Austin and Lu Li and Khalid Salama and Bartek Perz and Wooyeol Kim and Nandita Dukkipati and Anthony Baryshnikov and Christos Kaplanis and XiangHai Sheng and Yuri Chervonyi and Caglar Unlu and Diego de Las Casas and Harry Askham and Kathryn Tunyasuvunakool and Felix Gimeno and Siim Poder and Chester Kwak and Matt Miecnikowski and Vahab Mirrokni and Alek Dimitriev and Aaron Parisi and Dangyi Liu and Tomy Tsai and Toby Shevlane and Christina Kouridi and Drew Garmon and Adrian Goedeckemeyer and Adam R. Brown and Anitha Vijayakumar and Ali Elqursh and Sadegh Jazayeri and Jin Huang and Sara Mc Carthy and Jay Hoover and Lucy Kim and Sandeep Kumar and Wei Chen and Courtney Biles and Garrett Bingham and Evan Rosen and Lisa Wang and Qijun Tan and David Engel and Francesco Pongetti and Dario de Cesare and Dongseong Hwang and Lily Yu and Jennifer Pullman and Srini Narayanan and Kyle Levin and Siddharth Gopal and Megan Li and Asaf Aharoni and Trieu Trinh and Jessica Lo and Norman Casagrande and Roopali Vij and Loic Matthey and Bramandia Ramadhana and Austin Matthews and CJ Carey and Matthew Johnson and Kremena Goranova and Rohin Shah and Shereen Ashraf and Kingshuk Dasgupta and Rasmus Larsen and Yicheng Wang and Manish Reddy Vuyyuru and Chong Jiang and Joana Ijazi and Kazuki Osawa and Celine Smith and Ramya Sree Boppana and Taylan Bilal and Yuma Koizumi and Ying Xu and Yasemin Altun and Nir Shabat and Ben Bariach and Alex Korchemniy and Kiam Choo and Olaf Ronneberger and Chimezie Iwuanyanwu and Shubin Zhao and David Soergel and Cho-Jui Hsieh and Irene Cai and Shariq Iqbal and Martin Sundermeyer and Zhe Chen and Elie Bursztein and Chaitanya Malaviya and Fadi Biadsy and Prakash Shroff and Inderjit Dhillon and Tejasi Latkar and Chris Dyer and Hannah Forbes and Massimo Nicosia and Vitaly Nikolaev and Somer Greene and Marin Georgiev and Pidong Wang and Nina Martin and Hanie Sedghi and John Zhang and Praseem Banzal and Doug Fritz and Vikram Rao and Xuezhi Wang and Jiageng Zhang and Viorica Patraucean and Dayou Du and Igor Mordatch and Ivan Jurin and Lewis Liu and Ayush Dubey and Abhi Mohan and Janek Nowakowski and Vlad-Doru Ion and Nan Wei and Reiko Tojo and Maria Abi Raad and Drew A. Hudson and Vaishakh Keshava and Shubham Agrawal and Kevin Ramirez and Zhichun Wu and Hoang Nguyen and Ji Liu and Madhavi Sewak and Bryce Petrini and DongHyun Choi and Ivan Philips and Ziyue Wang and Ioana Bica and Ankush Garg and Jarek Wilkiewicz and Priyanka Agrawal and Xiaowei Li and Danhao Guo and Emily Xue and Naseer Shaik and Andrew Leach and Sadh MNM Khan and Julia Wiesinger and Sammy Jerome and Abhishek Chakladar and Alek Wenjiao Wang and Tina Ornduff and Folake Abu and Alireza Ghaffarkhah and Marcus Wainwright and Mario Cortes and Frederick Liu and Joshua Maynez and Andreas Terzis and Pouya Samangouei and Riham Mansour and Tomasz Kępa and François-Xavier Aubet and Anton Algymr and Dan Banica and Agoston Weisz and Andras Orban and Alexandre Senges and Ewa Andrejczuk and Mark Geller and Niccolo Dal Santo and Valentin Anklin and Majd Al Merey and Martin Baeuml and Trevor Strohman and Junwen Bai and Slav Petrov and Yonghui Wu and Demis Hassabis and Koray Kavukcuoglu and Jeff Dean and Oriol Vinyals},
      year={2024},
      eprint={2403.05530},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@article{wang_interpretability_2022,
      title={Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small}, 
      author={Kevin Wang and Alexandre Variengien and Arthur Conmy and Buck Shlegeris and Jacob Steinhardt},
      year={2022},
      eprint={2211.00593},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{meng_locating_2023,
      title={Locating and Editing Factual Associations in GPT}, 
      author={Kevin Meng and David Bau and Alex Andonian and Yonatan Belinkov},
      year={2023},
      eprint={2202.05262},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@article{rafailov_direct_2024,
      title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model}, 
      author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
      year={2024},
      eprint={2305.18290},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{touvron_llama2_2023,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
      eprint={2307.09288},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@misc{vicuna_2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@inproceedings{chao_jailbreakbench_2024,
  title={JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models},
  author={Patrick Chao and Edoardo Debenedetti and Alexander Robey and Maksym Andriushchenko and Francesco Croce and Vikash Sehwag and Edgar Dobriban and Nicolas Flammarion and George J. Pappas and Florian Tramèr and Hamed Hassani and Eric Wong},
  booktitle={NeurIPS Datasets and Benchmarks Track},
  year={2024}
}

@misc{arena, 
  title={Alignment Research Engineer Accelerator},
  author={James Hindmarch and Chloe Li and Callum McDougall and James Fox and David Quarel and Joly Scriven},
  year={2024}
}

@article{madry_deep_2019,
      title={Towards Deep Learning Models Resistant to Adversarial Attacks}, 
      author={Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
      year={2019},
      eprint={1706.06083},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
}

@article{goodfellow_explaining_2015,
      title={Explaining and Harnessing Adversarial Examples}, 
      author={Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
      year={2015},
      eprint={1412.6572},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
}

@article{lee_xjailbreak_2025,
      title={xJailbreak: Representation Space Guided Reinforcement Learning for Interpretable LLM Jailbreaking}, 
      author={Sunbowen Lee and Shiwen Ni and Chi Wei and Shuaimin Li and Liyang Fan and Ahmadreza Argha and Hamid Alinejad-Rokny and Ruifeng Xu and Yicheng Gong and Min Yang},
      year={2025},
      eprint={2501.16727},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}